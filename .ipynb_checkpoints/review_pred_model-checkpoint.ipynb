{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f6d8cde-bfc7-4e69-a107-896113140189",
   "metadata": {},
   "source": [
    "# importing liberies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda72d3d-4570-4b32-9642-5206dfbd1ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ca8d9-4750-4aca-b9a0-b78e6949792a",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01cb2bdf-8cdb-45ff-8318-d74320dc02ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/mnt/hdd/website_data/IMDB_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0764332-ee5c-4652-8e71-d083cceeb9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df.review\n",
    "labels = []\n",
    "for i in df.sentiment:\n",
    "    if i == \"positive\":\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515a9356-d5b0-47d3-9468-0c31c3aaa923",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = torch.tensor(labels, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b02cf36-60fe-40f4-8077-5fdad8d67da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec15a37a-af7b-483d-abe1-668726dc396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<oov>\")\n",
    "tokenizer.fit_on_texts(doc)\n",
    "sequences = tokenizer.texts_to_sequences(doc)\n",
    "x_train = pad_sequences(sequences,padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f791a906-7812-4405-89ad-014d3c06f06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.8000e+01, 5.0000e+00, 2.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [4.0000e+00, 3.9400e+02, 1.2100e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.1000e+01, 1.9100e+02, 1.2000e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [1.1000e+01, 2.3600e+02, 4.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.4600e+02, 1.6700e+02, 6.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [5.5000e+01, 2.8000e+01, 5.8930e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "671dd9df-04ed-4dca-9eac-3a0cdb9207e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 2493]), torch.Size([50000]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff1afcca-29fa-418a-83e4-73c5676080a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label = train_label.reshape(50000,1)\n",
    "train_label.dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2863e050-8f9e-406a-b1c7-681e5a61df8f",
   "metadata": {},
   "source": [
    "# Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fcd070e-a9bb-4010-a0d4-c5717f9e1304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm1 = nn.LSTM(2493,1000)\n",
    "        self.lstm2 = nn.LSTM(1000, 500)\n",
    "\n",
    "        self.dense1 = nn.Linear(500, 250)\n",
    "        self.dense2 = nn.Linear(250, 125)\n",
    "        self.dense3 = nn.Linear(125, 50)\n",
    "        self.dense4 = nn.Linear(50,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        out,_ = self.lstm1(x)\n",
    "        out,_ = self.lstm2(out)\n",
    "\n",
    "        x = self.dense1(out)\n",
    "        x = F.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dense3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dense4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5dfbe92-2c5d-43cf-97b6-18a2fb840c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM(\n",
       "  (lstm1): LSTM(2493, 1000)\n",
       "  (lstm2): LSTM(1000, 500)\n",
       "  (dense1): Linear(in_features=500, out_features=250, bias=True)\n",
       "  (dense2): Linear(in_features=250, out_features=125, bias=True)\n",
       "  (dense3): Linear(in_features=125, out_features=50, bias=True)\n",
       "  (dense4): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = LLM()\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa4a20ae-0141-4ec5-879f-c5b70e759572",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.compile(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab10e291-73ed-4bca-a7e8-097ee86b4607",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78ffe616-c906-4c41-bd35-1b2b21c5bf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): LLM(\n",
       "    (lstm1): LSTM(2493, 1000)\n",
       "    (lstm2): LSTM(1000, 500)\n",
       "    (dense1): Linear(in_features=500, out_features=250, bias=True)\n",
       "    (dense2): Linear(in_features=250, out_features=125, bias=True)\n",
       "    (dense3): Linear(in_features=125, out_features=50, bias=True)\n",
       "    (dense4): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2c6c756-829b-4591-96a4-ea36362a49b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([50000, 1])) that is different to the input size (torch.Size([])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(x_train)\n\u001b[0;32m----> 4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:621\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/torch/nn/functional.py:3163\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3161\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3164\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3166\u001b[0m     )\n\u001b[1;32m   3168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3169\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([50000, 1])) that is different to the input size (torch.Size([])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for i in range(epochs):\n",
    "    y_pred = model(x_train)\n",
    "    loss = loss_func(y_pred,train_label)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "367b7d54-e6f8-4ead-be1c-6f871e18671b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5194, 0.4956],\n",
       "        [0.5187, 0.4942],\n",
       "        [0.5185, 0.4935],\n",
       "        ...,\n",
       "        [0.5191, 0.4954],\n",
       "        [0.5188, 0.4957],\n",
       "        [0.5192, 0.4952]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f983d8fc-fd54-4411-9333-31d05f22340f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee7f6a4-4ec5-4be4-9c81-8b370525f565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58aa288a-1fd1-41ee-abf9-0911f721600c",
   "metadata": {},
   "source": [
    "# Research LSTM layer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b624422e-dad1-4a45-8f25-42fc91a369d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = nn.LSTM(2493,100)\n",
    "lstm_layer2 = nn.LSTM(100, 50)\n",
    "out, _= lstm_layer(x_train)\n",
    "out, _= lstm_layer2(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f88a1f12-7541-45ed-83ff-1427c0b2b93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 50])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7aea2ac-cdfb-4620-a7b3-a142dbed926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(50,2)\n",
    "\n",
    "output = fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d9d804c-9ad1-4078-bdf2-6c92cf65073e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0126, -0.0697],\n",
       "        [ 0.0180, -0.1441],\n",
       "        [-0.0959, -0.0897],\n",
       "        ...,\n",
       "        [ 0.0894, -0.1300],\n",
       "        [ 0.0697, -0.1123],\n",
       "        [-0.0038, -0.1127]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03dc296-59a2-4d92-af21-04c24fb8943b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727c489-2dab-4cf5-bf95-7ea97f2998d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
